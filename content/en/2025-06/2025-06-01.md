---
title: 06-01-Daily
weight: 30
breadcrumbs: false
comments: true
description: Recently, the Tongyi Lab Natural Language Intelligence team released
  and open-sourced VRAG-RL, a visual perception multimodal RAG reasoning framework.
  It aims to solve the challenge of AI retrieving key information from visual languages
  like images and tables and performing refined reasoning. Its...
---
# AI Insights Daily - June 1, 2025

1.  Recently, the **Tongyi Lab** Natural Language Intelligence team **released and open-sourced** **VRAG-RL**, a **visual perception multimodal RAG reasoning framework**. It aims to solve the challenge of **AI** retrieving key information from **visual languages** like images and tables and performing **refined reasoning**. Its reinforcement learning and innovative visual perception mechanisms significantly improve the understanding and retrieval efficiency of visual information. The framework has **performed excellently** on multiple benchmark datasets and is expected to improve the **generalization ability** of models in different visual tasks in the future. Check out this [link](https://github.com/Alibaba-NLP/VRAG) for more info.
2.  A research group at Arizona State University **published a paper** stating that **large language models** are not performing **true reasoning**, but are merely **finding correlations between data**, which may lead to **misunderstandings** among the public about how they work. The study emphasizes that in an era of increasing reliance on **AI**, we need to be more **cautious about** its capabilities. Future **AI research** is expected to move towards a more **explainable** direction.
3.  **Perplexity AI** has officially **launched Perplexity Labs**, bringing a brand new **AI productivity tool** with **multi-tool collaboration** to Pro subscribers, simplifying complex project development processes to just a few minutes. It aims to provide **end-to-end support** from idea to result. This feature, through **core capabilities** such as deep web browsing and code execution, marks Perplexity's transition from an answer engine to a **comprehensive AI production platform**.
4.  **Quark** recently **launched the "In-Depth Research" feature**. This feature relies on the **Tongyi Qianwen large model** to automatically complete the entire research process from data collection to **report generation** around complex topics such as academic subjects and industry analysis. This move marks a further leap for **AI** from an **information retrieval tool** to a **content creation partner**, providing **efficient support** for scenarios such as scientific research and market insights.
5.  **Alibaba Cloud** officially **released Tongyi Lingma AI IDE**, a native artificial intelligence development environment. With its powerful **programming intelligence mode**, **long-term memory**, and **inline suggestion prediction** functions, it significantly improves developer **programming efficiency**. The product is now **available for free download**, and its plugins have generated more than 3 billion lines of code, becoming a popular programming assistant tool and providing **strong support** for enterprise development work.
6.  **Memvid** is an **innovative AI memory tool** that achieves **sub-second fast semantic search** by **encoding text data into MP4 videos**, greatly saving storage space and supporting offline use. It has a built-in **chat function** and supports **PDF document import**, providing revolutionary **new possibilities** for fields such as **efficient knowledge management** and **academic research**. Check out this [link](https://github.com/Olow304/memvid) for more.
7.  Anthropic CEO Dario Amodei **warned** that **AI** could **replace half of entry-level white-collar jobs** in the next five years, leading to **unemployment rates soaring** to 10-20% and exacerbating **economic inequality**. He called for increased public **awareness** and **AI literacy** of **AI** development so that people can adapt to future career environments, and stressed that policymakers need to think about **solutions** in a super-intelligent economy.
8.  AI startup **Manus** has heavily **released the Manus Slides** function. Users only need a prompt word to **generate professional slides with one click**, covering a variety of scenarios such as business meetings and educational courses, greatly **improving the efficiency of presentation creation**. With its **intelligent generation** and **flexible editing** capabilities, it supports exporting to PowerPoint or PDF, marking a further evolution of **AI agents** from task automation to **productivity tools**.
9.  With **7086 stars** on GitHub, **prompt-eng-interactive-tutorial** is an open-source project of Anthropic's **interactive prompt engineering tutorial**, designed to help users **learn prompt engineering in a fun and effective way**. Check it out at this [link](https://github.com/anthropics/prompt-eng-interactive-tutorial).
10. The **onlook** project, which has **10143 stars**, is an **open-source visual atmosphere coding editor** that uses **AI** to help designers or developers **visually build**, **beautify, and edit React applications**. This tool is like a designer's **cursor**, making **React development** more **intuitive and efficient**. Check it out at this [link](https://github.com/onlook-dev/onlook).
11. The **anthropic-cookbook** project, with **12755 stars**, is a **collection of notebooks/cheatsheets** from Anthropic that **show how to use Claude in a fun and effective way**. It provides users with a variety of **Claude usage methods** and is a convenient [link](https://github.com/anthropics/anthropic-cookbook) for **learning and applying Claude**.
12. **MMSI-Bench** is a **VQA benchmark test** for **multi-image spatial intelligence**. Research has found that although multimodal large language models (MLLMs) have made progress, there is a **huge gap** between their accuracy (30-40%) and humans (97%) in **multi-image spatial reasoning**. The study diagnosed four major **failure modes** of the model, providing **valuable insights** for future improvement of **multi-image spatial intelligence**. See this [link](https://arxiv.org/abs/2505.23764) for details.
13. **ZeroGUI** is an innovative **online learning framework** that **automatically trains GUI agents at zero labor cost**. Through VLM-based automatic task generation and reward evaluation, it overcomes the **heavy reliance** on manual annotation in traditional GUI learning. Experiments have shown that the framework significantly improves the **performance** of **GUI agents** in different environments, bringing an **efficient solution** for **automated GUI operations**. See this [link](https://arxiv.org/abs/2505.23762) for details.
14. **ATLAS** is a high-capacity **long-term memory module** designed for **Transformer** architectures. It overcomes the limitations of existing models in **long sequence understanding** by optimizing the **memory context**, thereby learning the optimal memory strategy during testing. Experimental results show that **ATLAS** outperforms Transformer and linear recurrent models in tasks such as language modeling and long context understanding, significantly **improving performance**. See this [link](https://arxiv.org/abs/2505.23735) for details.

---

#### **Listen to the audio version**

| üéôÔ∏è **Xiaoyuzhou FM** | üìπ **Douyin** |
| --- | --- |
| [Laisheng Tavern](https://www.xiaoyuzhoufm.com/podcast/683c62b7c1ca9cf575a5030e)  |   [Laisheng Intelligence Station](https://www.douyin.com/user/MS4wLjABAAAAwpwqPQlu38sO38VyWgw9ZjDEnN4bMR5j8x111UxpseHR9DpB6-CveI5KRXOWuFwG)| 
| ![Â∞èÈÖíÈ¶Ü](https://s1.imagehub.cc/images/2025/06/24/f959f7984e9163fc50d3941d79a7f262.md.png) | ![ÊÉÖÊä•Á´ô](https://s1.imagehub.cc/images/2025/06/24/7fc30805eeb831e1e2baa3a240683ca3.md.png) |